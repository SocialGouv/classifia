# ==================================
# Albert LLM Configuration
# ==================================
# API key for Albert LLM service (French government AI)
ALBERT_API_KEY=sk-your_albert_api_key_here
# Albert API base URL
ALBERT_URL=https://albert.api.etalab.gouv.fr/v1

# ==================================
# Database Configuration
# ==================================
# PostgreSQL connection string with pgvector extension
# Format: postgresql://user:password@host:port/database
DATABASE_URL=postgresql://postgres:postgres@localhost:5999/classifia

# ==================================
# Redis Configuration
# ==================================
# Redis host for BullMQ job queue
REDIS_HOST=127.0.0.1
# Redis port
REDIS_PORT=6999

# ==================================
# Application Configuration
# ==================================
# Environment: development, test, or production
NODE_ENV=development
# Port for NestJS application
PORT=3000

# ==================================
# OpenAI Configuration
# ==================================
# Disable OpenAI Agents tracing (set to 1 to disable)
OPENAI_AGENTS_DISABLE_TRACING=1

# ==================================
# Crisp API Configuration
# ==================================
# Webhook secret for Crisp webhook authentication
CRISP_WEBHOOK_SECRET=your_crisp_webhook_secret_here
# Base64 encoded Crisp API key (format: identifier:key)
CRISP_API_KEY=your_base64_encoded_crisp_api_key_here
# Crisp API base URL with your website ID
CRISP_URL=https://api.crisp.chat/v1/website/your_website_id_here

# ==================================
# BullMQ Configuration
# ==================================
# Number of concurrent job processors
BULLMQ_CONCURRENCY=5
# Maximum number of retry attempts for failed jobs
BULLMQ_ATTEMPTS=3
# Delay in milliseconds before retrying a failed job
BULLMQ_BACKOFF_DELAY=30000
# Maximum number of jobs processed per minute (rate limiting)
BULLMQ_RATE_LIMIT=60

# ==================================
# Vector Similarity Thresholds
# ==================================
# Minimum similarity score to reuse existing subject (0.0-1.0)
VECTOR_SIMILARITY_REUSE=0.85
# Minimum similarity score to create an alias/grouping (0.0-1.0)
VECTOR_SIMILARITY_ALIAS=0.70

# ==================================
# Token & Processing Limits
# ==================================
# Maximum tokens per conversation for LLM processing
MAX_TOKENS_PER_CONVERSATION=2000
# Maximum number of labels/subjects per conversation
MAX_LABELS_PER_CONVERSATION=5
